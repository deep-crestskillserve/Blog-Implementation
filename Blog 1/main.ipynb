{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RdD21SzfvrNR"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ9nbgcNvvoG"
      },
      "outputs": [],
      "source": [
        "# Explicitly define AWS credentials in the session\n",
        "# Follow this step when running this on Google collab\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=\"AKIAQXUIXLSSGCYCWMLH\",\n",
        "    aws_secret_access_key=\"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\",\n",
        "    region_name=\"us-east-1\"\n",
        ")\n",
        "# Set up the Amazon Bedrock client\n",
        "bedrock_client = session.client(\"bedrock-runtime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Set up the Boto3 client to use the Amazon Bedrock runtime and specify the AWS Region:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the Amazon Bedrock client\n",
        "bedrock_client = boto3.client(\n",
        "    service_name=\"bedrock-runtime\",\n",
        "    region_name=\"us-east-1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Define the model to invoke using its model ID. In this example, we use Anthropicâ€™s Claude 3 Sonnet on Amazon Bedrock:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DAE8SMKZxmcv"
      },
      "outputs": [],
      "source": [
        "# Define the model ID\n",
        "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Assign a prompt, which is your message that will be used to interact with the FM at invocation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fcyt-74AxqMS"
      },
      "outputs": [],
      "source": [
        "# Prepare the input prompt\n",
        "prompt = \"Hello, how are you?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Define the payload as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bfvbYYwLxssx"
      },
      "outputs": [],
      "source": [
        "# Create the request payload\n",
        "payload = {\n",
        "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "    \"max_tokens\": 2048,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_k\": 250,\n",
        "    \"top_p\": 1,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": prompt\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. You have set the parameters and the FM you want to interact with. Now you send a request to Amazon Bedrock by providing the FM to interact with and the payload that you defined:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ISU-JA3Vxuap"
      },
      "outputs": [],
      "source": [
        "# Invoke the Amazon Bedrock model\n",
        "response = bedrock_client.invoke_model(\n",
        "    modelId=model_id,\n",
        "    body=json.dumps(payload)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. After the request is processed, you can display the result of the generated text from Amazon Bedrock:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ResponseMetadata': {'RequestId': '28e0f1de-b60d-46b0-9d6b-1f1f10d3fa10', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 27 Mar 2025 09:59:18 GMT', 'content-type': 'application/json', 'content-length': '417', 'connection': 'keep-alive', 'x-amzn-requestid': '28e0f1de-b60d-46b0-9d6b-1f1f10d3fa10', 'x-amzn-bedrock-invocation-latency': '2065', 'x-amzn-bedrock-output-token-count': '43', 'x-amzn-bedrock-input-token-count': '13'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0x0000020ED4692D70>}\n",
            "\n",
            "[{'type': 'text', 'text': \"Hello! As an AI language model, I don't have feelings, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\"}]\n",
            "\n",
            "Response: Hello! As an AI language model, I don't have feelings, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "print(response)\n",
        "print()\n",
        "result = json.loads(response[\"body\"].read())\n",
        "print(result[\"content\"])\n",
        "print()\n",
        "generated_text = \"\".join([output[\"text\"] for output in result[\"content\"]])\n",
        "print(f\"Response: {generated_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djux0P5pxwIm",
        "outputId": "a6430ebc-18ea-494d-e3b8-bcb01bf65aa9"
      },
      "outputs": [
        {
          "ename": "UnsupportedOperation",
          "evalue": "seek",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[47], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m response_body \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Reset the stream before reading\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mresponse_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Read response content (convert to string immediately)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     body_content \u001b[38;5;241m=\u001b[39m response_body\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response_body, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m response_body\n",
            "\u001b[1;31mUnsupportedOperation\u001b[0m: seek"
          ]
        }
      ],
      "source": [
        "# print(response)\n",
        "# print()\n",
        "\n",
        "if response and \"body\" in response and response[\"body\"]:\n",
        "    response_body = response[\"body\"]\n",
        "\n",
        "    try:\n",
        "        # Reset the stream before reading\n",
        "        response_body.seek(0)\n",
        "\n",
        "        # Read response content (convert to string immediately)\n",
        "        body_content = response_body.read().decode(\"utf-8\") if hasattr(response_body, \"read\") else response_body\n",
        "\n",
        "        if body_content:  # Check if the response body is not empty\n",
        "            # Parse JSON response\n",
        "            result = json.loads(body_content)\n",
        "            \n",
        "            # Extract content safely\n",
        "            content = result.get(\"content\", [])\n",
        "            print(content)\n",
        "            print()\n",
        "            \n",
        "            # Generate final text output safely\n",
        "            generated_text = \"\".join(output.get(\"text\", \"\") for output in content)\n",
        "            print(f\"Response: {generated_text}\")\n",
        "\n",
        "            # Reset the stream again in case it's needed for further operations\n",
        "            response_body.seek(0)\n",
        "        \n",
        "        else:\n",
        "            print(\"Error: Response body is empty.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Failed to decode JSON response. Raw response: {body_content}\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: No response body found.\")\n",
        "\n",
        "# response_body.seek(0)\n",
        "# print(result[\"content\"])\n",
        "# print()\n",
        "# generated_text = \"\".join([output[\"text\"] for output in result[\"content\"]])\n",
        "# print(f\"Response: {generated_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
